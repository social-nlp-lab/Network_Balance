{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from networkx import *\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import pickle, matplotlib\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undirected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import data\n",
    "# data = pd.read_csv(root)\n",
    "df = pd.read_csv(\"../data/unambiguous_enron_sentiment.csv\", header = 0)\n",
    "# mean of weights\n",
    "name = 'Average_sentiment_score'\n",
    "from_name = 'Name_From'\n",
    "to_name = 'Name_To'\n",
    "# averaging without consider direction of from to (used for undirected graph)\n",
    "df['nodes'] = df[[from_name, to_name]].values.tolist()\n",
    "df['nodes'] = df['nodes'].apply(lambda x: '--'.join(sorted(map(str, x))))\n",
    "df = df[['nodes', from_name, to_name, name]].groupby(['nodes'])[name].mean().reset_index()\n",
    "df[[from_name, to_name]] = df.nodes.apply(\n",
    "   lambda x: pd.Series(str(x).split(\"--\")))\n",
    "df[name] = df[name].replace(to_replace = [i for i in set(df[name]) if i>0], value =1)\n",
    "df[name] = df[name].replace(to_replace = [i for i in set(df[name]) if i<0], value =-1)\n",
    "df = df.drop(df[df[name] == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_all=nx.from_pandas_edgelist(df,source=from_name, target=to_name, edge_attr=name, create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "while(1):\n",
    "    G_all.remove_nodes_from(list(nx.isolates(G_all)))\n",
    "    remove = [node for node,degree in G_all.degree() if degree == 1]\n",
    "    G_all.remove_nodes_from(remove)\n",
    "    G_all.remove_edges_from(nx.selfloop_edges(G_all, data=True))\n",
    "    if c == number_of_edges(G_all):\n",
    "        break\n",
    "    else:\n",
    "        c = number_of_edges(G_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "info = []\n",
    "negative_edges = dict()\n",
    "for nodes in combinations(G_all.nodes, 3):\n",
    "    n_edges = G_all.subgraph(nodes).number_of_edges()\n",
    "    if n_edges == 3:\n",
    "        ratio = 1 if np.product([w[name] for n1, n2, w in G_all.subgraph(nodes).edges.data()]) == 1 else 0\n",
    "        info.append([G_all.subgraph(nodes).edges.data(), 'X', nodes, ratio])\n",
    "        negative_edges.setdefault([w[name] for n1, n2, w in G_all.subgraph(nodes).edges.data()].count(-1), 0)\n",
    "        negative_edges[[w[name] for n1, n2, w in G_all.subgraph(nodes).edges.data()].count(-1)]+=1\n",
    "info = pd.DataFrame(info)\n",
    "info.to_csv('../info_triads/Enron_sentiment_undirected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 6990, 1: 14958})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(info[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 6687, 0: 12717, 2: 2241, 3: 303}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7510, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/unambiguous_enron_sentiment.csv\", header = 0)\n",
    "name = 'Average_sentiment_score'\n",
    "from_name = 'Name_From'\n",
    "to_name = 'Name_To'\n",
    "# averaging by from to (used for directed graph)\n",
    "df = df[[from_name, to_name, name]].groupby([from_name, to_name]).mean().reset_index()\n",
    "\n",
    "df[name] = df[name].replace(to_replace = [i for i in set(df[name]) if i>0], value =1)\n",
    "df[name] = df[name].replace(to_replace = [i for i in set(df[name]) if i<0], value =-1)\n",
    "df = df.drop(df[df[name] == 0].index)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "## Get all triples in triads with respect to their census and edgelists (in edge_atts)\n",
    "def get_directed_triads(undirected_triad):\n",
    "    # Get all triplets of edges\n",
    "    list_tri = []\n",
    "    for candidate_edges in combinations(undirected_triad.edges.data(), 3):\n",
    "        # Get edges between unique pair of nodes\n",
    "        unique_edges = set([tuple(sorted((s,e))) for s,e,w in candidate_edges])\n",
    "        start_nodes = set([s for s,e,w in candidate_edges])\n",
    "        # Only consider triad in which the tree edges use a unique pair of nodes\n",
    "        if len(unique_edges) == 3 and len(start_nodes) !=3:\n",
    "            yield candidate_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_all=nx.from_pandas_edgelist(df,source=from_name, target=to_name, edge_attr=name, create_using=nx.DiGraph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "while(1):\n",
    "    G_all.remove_nodes_from(list(nx.isolates(G_all)))\n",
    "    remove = [node for node,degree in G_all.degree() if degree == 1]\n",
    "    G_all.remove_nodes_from(remove)\n",
    "    G_all.remove_edges_from(nx.selfloop_edges(G_all, data=True))\n",
    "    if c == number_of_edges(G_all):\n",
    "        break\n",
    "    else:\n",
    "        c = number_of_edges(G_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_all=nx.from_pandas_edgelist(df,source=from_name, target=to_name, edge_attr=name, create_using=nx.DiGraph())\n",
    "useless_census = ['003','012', '102', '021D', '021C', '021U', '021', '111U', '111D', '201', '030C', '120C', '210']\n",
    "info = []\n",
    "balances = []\n",
    "unbalances = []\n",
    "for triads in all_triads(G_all):\n",
    "    if triad_type(triads) not in useless_census:\n",
    "        all_values = {1:0, 0:0, -1:0}\n",
    "        for triangle in get_directed_triads(triads):\n",
    "            all_values[np.product([w[name] for n1, n2, w in triangle])] += 1\n",
    "        ratio = all_values[1]/(all_values[1]+all_values[-1])\n",
    "        info.append([triads.edges.data(), triad_type(triads), set([k[0] for k in triads.edges.data()]+[k[1] for k in triads.edges.data()]), ratio])\n",
    "        \n",
    "        balance_list = []\n",
    "        if triad_type(triads) == '300':\n",
    "            for triangle in get_directed_triads(triads):\n",
    "                node = []\n",
    "                for edge in triangle:\n",
    "                    if edge[0] not in node:\n",
    "                        node.append(edge[0])\n",
    "                if len(node) != 3:\n",
    "                    balance = 1\n",
    "                    for edge in triangle:\n",
    "                        balance *= edge[2][name]\n",
    "                    balance_list.append(balance)\n",
    "        else:\n",
    "            for item in get_directed_triads(triads):\n",
    "                balance = 1\n",
    "                for edge in item:\n",
    "                    balance *= edge[2][name]\n",
    "                balance_list.append(balance)\n",
    "        if -1 in balance_list:\n",
    "            unbalances.append(triads)\n",
    "        else:\n",
    "            balances.append(triads)\n",
    "\n",
    "info = pd.DataFrame(info)\n",
    "info.to_csv('../info_triads/Enron_sentiment_directed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(info[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of balanced traids\n",
    "dict_balance = dict()\n",
    "for i in balances:\n",
    "    for triangle in get_directed_triads(i):\n",
    "        if [e[2][name] for e in triangle].count(-1) not in dict_balance.keys():\n",
    "            dict_balance[[e[2][name] for e in triangle].count(-1)]=0\n",
    "        dict_balance[[e[2][name] for e in triangle].count(-1)]+=1\n",
    "print(dict_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of imbalance triads\n",
    "dict_unbalance = {}\n",
    "for i in unbalances:\n",
    "    for triangle in get_directed_triads(i):\n",
    "        if [e[2][name] for e in triangle].count(-1) not in dict_unbalance.keys():\n",
    "            dict_unbalance[[e[2][name] for e in triangle].count(-1)]=0\n",
    "        dict_unbalance[[e[2][name] for e in triangle].count(-1)]+=1\n",
    "print(dict_unbalance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
